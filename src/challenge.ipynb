{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Enfoque y lógica soluciones *q_time*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_time* del challenge, el enfoque se centra en optimizar el tiempo de ejecución. Utilizado la biblioteca **Polars**, que es una biblioteca de manipulación de datos de alto rendimiento y baja memoria se realizó la lectura y procesamiento de los datos.\n",
    "\n",
    "Polars utiliza una estructura de datos llamada LazyFrame que es similar a la de Pandas, pero utiliza un enfoque de evaluación perezosa (lazy evaluation), lo que significa que las operaciones no se ejecutan inmediatamente, sino que se almacenan en un plan de ejecución y sólo se realizan cuando se necesita el resultado. Esto puede llevar a un uso más eficiente de los recursos y a un mejor rendimiento.\n",
    "\n",
    "**Mejoras al enfoque:** \n",
    "- Se podría utilizar servicios de almacenamiento en la nube como *Google Cloud Storage* o *Amazon S3* para almacenar el conjunto de datos. De esta forma la carga de los datos no pasan por la memoria de una sola máquina.\n",
    "\n",
    "- Podríamos utilizar servicios de Big Data y análisis como *Google BigQuery* o *Amazon Redshift* para procesar el conjunto de datos. Estos servicios están diseñados para trabajar con grandes conjuntos de datos y pueden realizar operaciones de agrupamiento y conteo de manera muy rápida.\n",
    "\n",
    "En general si se elige un enfoque utilizando herramientas en la nube podriamos aprovechar el conjunto de herramientas que ofrecen las diferentes suits como GCP, AWS, Azure y que interactuan de manera muy eficiente entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enfoque y lógica soluciones *q_memory*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_memory* del challenge el enfoque se centra en optimizar el uso de la memoria. En lugar de cargar todos los datos en la memoria a la vez, se leen los datos en trozos (chunks) de 1000 filas a la vez utilizando la función *read_json* de **Pandas** con el parámetro *chunksize*.\n",
    "\n",
    "En la inspección previa del archivo pudimos ver que son más de 117000 lineas de tweets, entonces utilizaremos chunks de tamaño 1000 para tener un balance entre un buen tiempo de ejecución y bajo consumo de memoría.\n",
    "\n",
    "En cuanto al filtrado y procesamiento de los datos utilizamos las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "Este enfoque es más eficiente en términos de uso de memoria, ya que sólo mantiene en memoria los contadores y el chunk actual de datos. Sin embargo, puede ser más lento que el enfoque q1_time, especialmente para conjuntos de datos muy grandes, ya que tiene que leer los datos en múltiples pasos.\n",
    "\n",
    "**Mejoras al enfoque:**\n",
    "\n",
    "- El uso de herramientas como **Apache Spark** en la nube son especialmente utiles para el procesamiento paralelo de grandes conjuntos de datos. Por ejemplo *Google Cloud Dataproc* (de GCP) o *Amazon EMR* de (AWS) son servicios permiten ejecutar trabajos de Apache Spark en la nube.\n",
    "\n",
    "- *Paralelización:* Podríamos mejorar el rendimiento de este enfoque utilizando procesamiento paralelo o concurrente. Por ejemplo, podríamos procesar varios chunks de datos simultáneamente en diferentes hilos o procesos.\n",
    "\n",
    "- Ajuste del tamaño del chunk: El tamaño del chunk seteado a 1000 fue elegido arbitrariamente. Podríamos experimentar con diferentes tamaños de chunk para encontrar el óptimo entre el tiempo de ejecución y el uso de memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras una inspección al conjunto de datos y las preguntas que se plantean en el desafío, podemos concluir que los campos que se utilizarán son los siguientes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Índices que se utilizarán:\n",
    "\n",
    "|Atributo|Descripción|Data type|Sub-elementos|\n",
    "|--------|--------|--------|--------|\n",
    "|date|Fecha cuando el tweet fue creado|String|-|\n",
    "|user|Objeto con los datos del usuario que creó el tweet|User object|username (String)|\n",
    "|content|Contenido del tweet|String|-|\n",
    "|mentionedUsers|Lista de objetos con los datos de los usuarios mencionados en el tweet|List of User objects|username (String)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observaciones\n",
    "\n",
    "- **content:** El elemento *content* que utilizarémos para la pregunta 2 del desafío contiene todo el contenido del tweet, incluyendo enlaces y menciones a usuarios, por lo que sería una buena practica realizar una limpieza de URLS y menciones antes de realizar el análisis.\n",
    "\n",
    "- **created_at**: El atributo *created_at* que aparece en la documentación entregada para el desafió no está presente en el conjunto de datos, en su lugar está el atributo \"date\" que simboliza lo mismo, la fecha en la que se creó el tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "#Funciones desarrolladas\n",
    "from q1_time import q1_time, q1_time_pandas\n",
    "from q1_memory import q1_memory\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Listar las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecución, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los métodos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Seleccionar las columnas relevantes.\n",
    "- Agrupamos los datos por por fecha y usuario.\n",
    "- Contar el número de tweets para cada combinación de fecha y usuario.\n",
    "- Seleccionar las 10 fechas con más tweets.\n",
    "- Luego iteramos en estas fechas y seleccionar los usuarios con la mayor cantidad de tweets en esos días.\n",
    "- Se contruye una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time = q1_time(file_path)\n",
    "display(resultado_q1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83 s ± 87.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 1677.14 MiB, increment: 522.91 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)\n",
    "%memit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q1_time** tiene un tiempo de ejecución promedio de *2.8 segundos* y uso máximo de memoría de *1677 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta solución se leen los datos en chunks y aprovechando las iteraciones para cada chunk, actualiza dos contadores: uno para el conteo de tweets por fecha y otro para el conteo de tweets por usuario para cada fecha. Estos contadores se implementan utilizando las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Definir el tamaño del chunk y los contadores.\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Actualizar los contadores.\n",
    "- Obtener las 10 fechas con más tweets.\n",
    "- Seleccionar el usuario con más tweets para cada fecha.\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_memory = q1_memory(file_path)\n",
    "display(resultado_q1_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 s ± 175 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 157.44 MiB, increment: 15.60 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory(file_path)\n",
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q1_memory** tiene un tiempo de ejecución promedio de *4.4 segundos* y un uso máximo de memoría de *157 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time_pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como extra mencionar que durante el desarrollo del challenge se intentó utilizar la librería pandas para los enfoques *time* enfoque que no cuida el uso de memoría, pero esta librería tardaba mucho tiempo en leer el conjunto de datos. Por lo que se barajó utilizar la librería **Polars** con su metodo LazyFrame, que es es más rápido que un DataFrame de Pandas gracias a su enfoque de procesamiento perezoso (lazy) que optimiza las operaciones y su capacidad de computación en paralelo aprovechando múltiples núcleos de CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time_pandas= q1_time_pandas(file_path)\n",
    "display(resultado_q1_time_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 s ± 583 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 2805.34 MiB, increment: 2319.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_pandas(file_path)\n",
    "%memit q1_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el uso de memoria y el tiempo de computo utilizando Pandas es mayor que utilizando la librería Polars. 5.11 segundos y 2805 MiB de memoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q2_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecución, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los métodos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "Además antes de procesor el conjunto de datos en busca de los emojis haremos una limpieza para eliminar las URLs y las menciones de usuarios en el texto del tweet usando una expresión regular. Esto hará que la función *extract_emojis* tenga menos texto que procesar.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Leer el conjunto de datos en un LazyFrame de Polars\n",
    "- Eliminar los URLs y las menciones de usuario del texto del tweet usando una expresión regular.\n",
    "- Seleccionar las columna relevante (\"content\") y aplica extract_emojis a cada fila (devuelve una lista de emojis de un texto).\n",
    "- Filtra las filas del DataFrame para eliminar aquellas que no contienen emojis.\n",
    "- Aplicamos la función explode() para tener un DataFrame donde cada fila corresponde a un solo emoji\n",
    "- Agrupamos los datos por \"emojis\".\n",
    "- Contar el número de veces que cada emoji aparece.\n",
    "- Seleccionar los 10 emojis más usados.\n",
    "- Se devuelve una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5046),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2970),\n",
       " ('🌾', 2181),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1665),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q2_time = q2_time(file_path)\n",
    "display(resultado_q2_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.23 s ± 220 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 565.34 MiB, increment: 340.73 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_time(file_path)\n",
    "%memit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q2_time** tiene un tiempo de ejecución promedio de *7.2 segundos* y uso máximo de memoría de *565 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q2_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta solución se leen los datos en chunks y aprovechando las iteraciones para cada chunk, actualiza dos contadores: uno para el conteo de tweets por fecha y otro para el conteo de tweets por usuario para cada fecha. Estos contadores se implementan utilizando las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Definir el tamaño del chunk y crear un contador para los emojis (emoji_counts).\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Usar la función *emoji_list* de la librería emoji para extraer los emojis en cada tweet\n",
    "- Actualizar los contadores de emojis.\n",
    "- Obtener los 10 emojis que más se usaron en los tweets desde el contador usando el método most_common(10).\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q2_memory = q2_memory(file_path)\n",
    "display(resultado_q2_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 s ± 323 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 156.49 MiB, increment: 14.55 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_memory(file_path)\n",
    "%memit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q2_memory** tiene un tiempo de ejecución promedio de *10.9 segundos* y uso máximo de memoría de *156 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q3_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecución, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los métodos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Leer el conjunto de datos en un LazyFrame de Polars\n",
    "- Explosión de la columna *mentionedUsers* para poder contar cada mención por separado.\n",
    "- Extraemos el *username* de cada usuario mencionado y se almacenan en una nueva columna *username*.\n",
    "- Agrupar los datos por la nueva columna *username* y se realiza el conteo de menciones.\n",
    "- Ordenamos y obtenemos el top 10 de usuarios más mencionados con *limit(10)*.\n",
    "- Se devuelve una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q3_time = q3_time(file_path)\n",
    "display(resultado_q3_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.63 s ± 99.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 1410.25 MiB, increment: 804.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_time(file_path)\n",
    "%memit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q3_time** tiene un tiempo de ejecución promedio de *2.6 segundos* y uso máximo de memoría de *1410 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q3_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta solución se leen los datos en chunks y aprovechando las iteraciones para cada chunk, se actualiza un contador con las menciones de cada usuario. Este contador se implementa utilizando la clase *Counter* de la biblioteca **Collections**, que proporciona una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realizó la función es:\n",
    "- Definir el tamaño del chunk y crear el contador que almacenará las menciones (user_mention_counts).\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Explosión de menciones para poder contar cada mención por separado y eliminamos filas que no tengan menciones.\n",
    "- Extraemos el *username* de cada mención y lo almacenamos en una nueva columna llamada 'username'.\n",
    "- Actualizar el contador.\n",
    "- Obtenemos los 10 usuarios con más menciones desde el contador, con el método *most_common(10)*.\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q3_memory = q3_memory(file_path)\n",
    "display(resultado_q3_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 s ± 53.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 150.80 MiB, increment: 10.68 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_memory(file_path)\n",
    "%memit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q3_memory** tiene un tiempo de ejecución promedio de *4.6 segundos* y uso máximo de memoría de *150 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Estructura del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se siguió la misma estructura definida en el challenge, agregando una carpeta donde se almacenaron los datos\n",
    "\n",
    "```css\n",
    "├── README.md\n",
    "├── requirements.txt\n",
    "├── LICENSE\n",
    "├── data\n",
    "│   └── farmers-protest-tweets-2021-2-4.json\n",
    "└── src\n",
    "    ├── challenge.ipynb\n",
    "    ├── q1_time.py\n",
    "    ├── q1_memory.py\n",
    "    ├── q2_time.py\n",
    "    ├── q2_memory.py\n",
    "    ├── q3_time.py\n",
    "    ├── q3_memory.py\n",
    "    └── utils.py\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### POST para enviar el desafío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desafío enviado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "   \"name\": \"Victor Gatica\",\n",
    "   \"mail\": \"gaticavm9@gmail.com\",\n",
    "   \"github_url\": \"https://github.com/gaticavm9/DE-Challenge-Victor-Gatica.git\"\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\", json=data)\n",
    "\n",
    "# Verifica que la solicitud se haya realizado correctamente\n",
    "if response.status_code == 200:\n",
    "   print(\"Desafío enviado correctamente.\")\n",
    "else:\n",
    "   print(f\"Hubo error: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
