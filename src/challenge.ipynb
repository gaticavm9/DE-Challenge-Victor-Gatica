{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Enfoque y l√≥gica soluciones *q_time*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_time* del challenge, el enfoque se centra en optimizar el tiempo de ejecuci√≥n. Utilizado la biblioteca **Polars**, que es una biblioteca de manipulaci√≥n de datos de alto rendimiento y baja memoria se realiz√≥ la lectura y procesamiento de los datos.\n",
    "\n",
    "Polars utiliza una estructura de datos llamada LazyFrame que es similar a la de Pandas, pero utiliza un enfoque de evaluaci√≥n perezosa (lazy evaluation), lo que significa que las operaciones no se ejecutan inmediatamente, sino que se almacenan en un plan de ejecuci√≥n y s√≥lo se realizan cuando se necesita el resultado. Esto puede llevar a un uso m√°s eficiente de los recursos y a un mejor rendimiento.\n",
    "\n",
    "**Mejoras al enfoque:** \n",
    "- Se podr√≠a utilizar servicios de almacenamiento en la nube como *Google Cloud Storage* o *Amazon S3* para almacenar el conjunto de datos. De esta forma la carga de los datos no pasan por la memoria de una sola m√°quina.\n",
    "\n",
    "- Podr√≠amos utilizar servicios de Big Data y an√°lisis como *Google BigQuery* o *Amazon Redshift* para procesar el conjunto de datos. Estos servicios est√°n dise√±ados para trabajar con grandes conjuntos de datos y pueden realizar operaciones de agrupamiento y conteo de manera muy r√°pida.\n",
    "\n",
    "En general si se elige un enfoque utilizando herramientas en la nube podriamos aprovechar el conjunto de herramientas que ofrecen las diferentes suits como GCP, AWS, Azure y que interactuan de manera muy eficiente entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enfoque y l√≥gica soluciones *q_memory*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_memory* del challenge el enfoque se centra en optimizar el uso de la memoria. En lugar de cargar todos los datos en la memoria a la vez, se leen los datos en trozos (chunks) de 1000 filas a la vez utilizando la funci√≥n *read_json* de **Pandas** con el par√°metro *chunksize*.\n",
    "\n",
    "En la inspecci√≥n previa del archivo pudimos ver que son m√°s de 117000 lineas de tweets, entonces utilizaremos chunks de tama√±o 1000 para tener un balance entre un buen tiempo de ejecuci√≥n y bajo consumo de memor√≠a.\n",
    "\n",
    "En cuanto al filtrado y procesamiento de los datos utilizamos las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "Este enfoque es m√°s eficiente en t√©rminos de uso de memoria, ya que s√≥lo mantiene en memoria los contadores y el chunk actual de datos. Sin embargo, puede ser m√°s lento que el enfoque q1_time, especialmente para conjuntos de datos muy grandes, ya que tiene que leer los datos en m√∫ltiples pasos.\n",
    "\n",
    "**Mejoras al enfoque:**\n",
    "\n",
    "- El uso de herramientas como **Apache Spark** en la nube son especialmente utiles para el procesamiento paralelo de grandes conjuntos de datos. Por ejemplo *Google Cloud Dataproc* (de GCP) o *Amazon EMR* de (AWS) son servicios permiten ejecutar trabajos de Apache Spark en la nube.\n",
    "\n",
    "- *Paralelizaci√≥n:* Podr√≠amos mejorar el rendimiento de este enfoque utilizando procesamiento paralelo o concurrente. Por ejemplo, podr√≠amos procesar varios chunks de datos simult√°neamente en diferentes hilos o procesos.\n",
    "\n",
    "- Ajuste del tama√±o del chunk: El tama√±o del chunk seteado a 1000 fue elegido arbitrariamente. Podr√≠amos experimentar con diferentes tama√±os de chunk para encontrar el √≥ptimo entre el tiempo de ejecuci√≥n y el uso de memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Exploraci√≥n de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras una inspecci√≥n al conjunto de datos y las preguntas que se plantean en el desaf√≠o, podemos concluir que los campos que se utilizar√°n son los siguientes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### √çndices que se utilizar√°n:\n",
    "\n",
    "|Atributo|Descripci√≥n|Data type|Sub-elementos|\n",
    "|--------|--------|--------|--------|\n",
    "|date|Fecha cuando el tweet fue creado|String|-|\n",
    "|user|Objeto con los datos del usuario que cre√≥ el tweet|User object|username (String)|\n",
    "|content|Contenido del tweet|String|-|\n",
    "|mentionedUsers|Lista de objetos con los datos de los usuarios mencionados en el tweet|List of User objects|username (String)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observaciones\n",
    "\n",
    "- **content:** El elemento *content* que utilizar√©mos para la pregunta 2 del desaf√≠o contiene todo el contenido del tweet, incluyendo enlaces y menciones a usuarios, por lo que ser√≠a una buena practica realizar una limpieza de URLS y menciones antes de realizar el an√°lisis.\n",
    "\n",
    "- **created_at**: El atributo *created_at* que aparece en la documentaci√≥n entregada para el desafi√≥ no est√° presente en el conjunto de datos, en su lugar est√° el atributo \"date\" que simboliza lo mismo, la fecha en la que se cre√≥ el tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "#Funciones desarrolladas\n",
    "from q1_time import q1_time, q1_time_pandas\n",
    "from q1_memory import q1_memory\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Listar las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecuci√≥n, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los m√©todos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Seleccionar las columnas relevantes.\n",
    "- Agrupamos los datos por por fecha y usuario.\n",
    "- Contar el n√∫mero de tweets para cada combinaci√≥n de fecha y usuario.\n",
    "- Seleccionar las 10 fechas con m√°s tweets.\n",
    "- Luego iteramos en estas fechas y seleccionar los usuarios con la mayor cantidad de tweets en esos d√≠as.\n",
    "- Se contruye una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time = q1_time(file_path)\n",
    "display(resultado_q1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83 s ¬± 87.7 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 1677.14 MiB, increment: 522.91 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)\n",
    "%memit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q1_time** tiene un tiempo de ejecuci√≥n promedio de *2.8 segundos* y uso m√°ximo de memor√≠a de *1677 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta soluci√≥n se leen los datos en chunks y aprovechando las iteraciones para cada chunk, actualiza dos contadores: uno para el conteo de tweets por fecha y otro para el conteo de tweets por usuario para cada fecha. Estos contadores se implementan utilizando las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Definir el tama√±o del chunk y los contadores.\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Actualizar los contadores.\n",
    "- Obtener las 10 fechas con m√°s tweets.\n",
    "- Seleccionar el usuario con m√°s tweets para cada fecha.\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_memory = q1_memory(file_path)\n",
    "display(resultado_q1_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 s ¬± 175 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 157.44 MiB, increment: 15.60 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory(file_path)\n",
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q1_memory** tiene un tiempo de ejecuci√≥n promedio de *4.4 segundos* y un uso m√°ximo de memor√≠a de *157 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time_pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como extra mencionar que durante el desarrollo del challenge se intent√≥ utilizar la librer√≠a pandas para los enfoques *time* enfoque que no cuida el uso de memor√≠a, pero esta librer√≠a tardaba mucho tiempo en leer el conjunto de datos. Por lo que se baraj√≥ utilizar la librer√≠a **Polars** con su metodo LazyFrame, que es es m√°s r√°pido que un DataFrame de Pandas gracias a su enfoque de procesamiento perezoso (lazy) que optimiza las operaciones y su capacidad de computaci√≥n en paralelo aprovechando m√∫ltiples n√∫cleos de CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time_pandas= q1_time_pandas(file_path)\n",
    "display(resultado_q1_time_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 s ¬± 583 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 2805.34 MiB, increment: 2319.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_pandas(file_path)\n",
    "%memit q1_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el uso de memoria y el tiempo de computo utilizando Pandas es mayor que utilizando la librer√≠a Polars. 5.11 segundos y 2805 MiB de memor√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Los top 10 emojis m√°s usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q2_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecuci√≥n, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los m√©todos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "Adem√°s antes de procesor el conjunto de datos en busca de los emojis haremos una limpieza para eliminar las URLs y las menciones de usuarios en el texto del tweet usando una expresi√≥n regular. Esto har√° que la funci√≥n *extract_emojis* tenga menos texto que procesar.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Leer el conjunto de datos en un LazyFrame de Polars\n",
    "- Eliminar los URLs y las menciones de usuario del texto del tweet usando una expresi√≥n regular.\n",
    "- Seleccionar las columna relevante (\"content\") y aplica extract_emojis a cada fila (devuelve una lista de emojis de un texto).\n",
    "- Filtra las filas del DataFrame para eliminar aquellas que no contienen emojis.\n",
    "- Aplicamos la funci√≥n explode() para tener un DataFrame donde cada fila corresponde a un solo emoji\n",
    "- Agrupamos los datos por \"emojis\".\n",
    "- Contar el n√∫mero de veces que cada emoji aparece.\n",
    "- Seleccionar los 10 emojis m√°s usados.\n",
    "- Se devuelve una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 5046),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2970),\n",
       " ('üåæ', 2181),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1665),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q2_time = q2_time(file_path)\n",
    "display(resultado_q2_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.23 s ¬± 220 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 565.34 MiB, increment: 340.73 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_time(file_path)\n",
    "%memit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q2_time** tiene un tiempo de ejecuci√≥n promedio de *7.2 segundos* y uso m√°ximo de memor√≠a de *565 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q2_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta soluci√≥n se leen los datos en chunks y aprovechando las iteraciones para cada chunk, actualiza dos contadores: uno para el conteo de tweets por fecha y otro para el conteo de tweets por usuario para cada fecha. Estos contadores se implementan utilizando las clases *Counter* y *defaultdict* de la biblioteca **Collections**, que proporcionan una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Definir el tama√±o del chunk y crear un contador para los emojis (emoji_counts).\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Usar la funci√≥n *emoji_list* de la librer√≠a emoji para extraer los emojis en cada tweet\n",
    "- Actualizar los contadores de emojis.\n",
    "- Obtener los 10 emojis que m√°s se usaron en los tweets desde el contador usando el m√©todo most_common(10).\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q2_memory = q2_memory(file_path)\n",
    "display(resultado_q2_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 s ¬± 323 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 156.49 MiB, increment: 14.55 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_memory(file_path)\n",
    "%memit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q2_memory** tiene un tiempo de ejecuci√≥n promedio de *10.9 segundos* y uso m√°ximo de memor√≠a de *156 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q3_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecuci√≥n, cargamos el archivo completo en un *LazyFrame* de **Polars** y utilizamos los m√©todos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Leer el conjunto de datos en un LazyFrame de Polars\n",
    "- Explosi√≥n de la columna *mentionedUsers* para poder contar cada menci√≥n por separado.\n",
    "- Extraemos el *username* de cada usuario mencionado y se almacenan en una nueva columna *username*.\n",
    "- Agrupar los datos por la nueva columna *username* y se realiza el conteo de menciones.\n",
    "- Ordenamos y obtenemos el top 10 de usuarios m√°s mencionados con *limit(10)*.\n",
    "- Se devuelve una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q3_time = q3_time(file_path)\n",
    "display(resultado_q3_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.63 s ¬± 99.1 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 1410.25 MiB, increment: 804.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_time(file_path)\n",
    "%memit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q3_time** tiene un tiempo de ejecuci√≥n promedio de *2.6 segundos* y uso m√°ximo de memor√≠a de *1410 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q3_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta soluci√≥n se leen los datos en chunks y aprovechando las iteraciones para cada chunk, se actualiza un contador con las menciones de cada usuario. Este contador se implementa utilizando la clase *Counter* de la biblioteca **Collections**, que proporciona una forma eficiente de contar elementos.\n",
    "\n",
    "El desglose de lo que realiz√≥ la funci√≥n es:\n",
    "- Definir el tama√±o del chunk y crear el contador que almacenar√° las menciones (user_mention_counts).\n",
    "- Leer el archivo JSON en chunks.\n",
    "- Explosi√≥n de menciones para poder contar cada menci√≥n por separado y eliminamos filas que no tengan menciones.\n",
    "- Extraemos el *username* de cada menci√≥n y lo almacenamos en una nueva columna llamada 'username'.\n",
    "- Actualizar el contador.\n",
    "- Obtenemos los 10 usuarios con m√°s menciones desde el contador, con el m√©todo *most_common(10)*.\n",
    "- Construir una lista de tuplas con la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q3_memory = q3_memory(file_path)\n",
    "display(resultado_q3_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tard√≥ nuestra funci√≥n en encontrar el resultado y el peak m√°ximo de memor√≠a que utiliz√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 s ¬± 53.2 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 150.80 MiB, increment: 10.68 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_memory(file_path)\n",
    "%memit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la funci√≥n **q3_memory** tiene un tiempo de ejecuci√≥n promedio de *4.6 segundos* y uso m√°ximo de memor√≠a de *150 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Estructura del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se sigui√≥ la misma estructura definida en el challenge, agregando una carpeta donde se almacenaron los datos\n",
    "\n",
    "```css\n",
    "‚îú‚îÄ‚îÄ README.md\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îú‚îÄ‚îÄ LICENSE\n",
    "‚îú‚îÄ‚îÄ data\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ farmers-protest-tweets-2021-2-4.json\n",
    "‚îî‚îÄ‚îÄ src\n",
    "    ‚îú‚îÄ‚îÄ challenge.ipynb\n",
    "    ‚îú‚îÄ‚îÄ q1_time.py\n",
    "    ‚îú‚îÄ‚îÄ q1_memory.py\n",
    "    ‚îú‚îÄ‚îÄ q2_time.py\n",
    "    ‚îú‚îÄ‚îÄ q2_memory.py\n",
    "    ‚îú‚îÄ‚îÄ q3_time.py\n",
    "    ‚îú‚îÄ‚îÄ q3_memory.py\n",
    "    ‚îî‚îÄ‚îÄ utils.py\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### POST para enviar el desaf√≠o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desaf√≠o enviado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "   \"name\": \"Victor Gatica\",\n",
    "   \"mail\": \"gaticavm9@gmail.com\",\n",
    "   \"github_url\": \"https://github.com/gaticavm9/DE-Challenge-Victor-Gatica.git\"\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\", json=data)\n",
    "\n",
    "# Verifica que la solicitud se haya realizado correctamente\n",
    "if response.status_code == 200:\n",
    "   print(\"Desaf√≠o enviado correctamente.\")\n",
    "else:\n",
    "   print(f\"Hubo error: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
