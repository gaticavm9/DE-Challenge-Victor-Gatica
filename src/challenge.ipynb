{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "#Funciones desarrolladas\n",
    "from q1_time import q1_time, q1_time_pandas\n",
    "from q1_memory import q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Enfoque y lógica soluciones *q_time*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_time* del challenge el enfoque utilizado fue realizar la lectura y procesamiento de los datos con la librería **Polars** y aprovechar el uso de su estructura Lazy Frame que está bien optimizada para aprovechar el rendimiento del computador y procesar conjuntos de datos de gran tamaño.\n",
    "\n",
    "**Mejoras al enfoque:** Manejo de librerias como apache spark para el procesamiento de los datos, esto permitiría el uso de spark para el procesamiento de los datos y el uso de un bucket de GCP para el almacenamiento de los archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enfoque y lógica soluciones *q_memory*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las soluciones *q_memory* del challenge el enfoque utilizado fue realizar la lectura y procesamiento de los datos con la librería **Pandas** y utilizando su metodo chunk para la lectura del conjunto de datos.\n",
    "\n",
    "Para optimizar el uso de memoria en nuestras funciónes vamos a procesar el conjunto de datos en chunks. Como en la inspección previa del archivo pudimos ver que son más de 117000 lineas de tweets, utilizaremos chunks de tamaño 1000 para tener un balance entre un buen tiempo de ejecución y bajo consumo de memoría.\n",
    "\n",
    "En cuanto al filtrado y procesamiento de los datos utilizamos la libería collections de python con su metodo Counter() el cual es bastante bajo en uso de memoria y en conjunto a las iteraciones realizadas por los chunks procesamos los datos de manera eficiente.\n",
    "\n",
    "**Mejoras al enfoque:** Manejo de librerias como apache spark para el procesamiento de los datos, esto permitiría el uso de spark para el procesamiento de los datos y el uso de un bucket de GCP para el almacenamiento de los archivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pregunta nro 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Listar las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el tiempo de ejecución, cargamos el archivo completo en un Lazy Frame de Polars y utilizamos los métodos de esta libreria ya que son eficientes para el procesamiento de datos ordenados.\n",
    "\n",
    "-Agrupamos los tweets por fecha y recuperamos las 10 fechas con más tweets\n",
    "-Luego iteramos en estas fechas y buscamos los usuarios con la mayor cantidad de tweets en esos días\n",
    "-Vamos construyendo una lista de tuplas con la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time = q1_time(file_path)\n",
    "display(resultado_q1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83 s ± 87.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 1677.14 MiB, increment: 522.91 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)\n",
    "%memit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q1_time** tiene un tiempo de ejecución promedio de *2.8 segundos* y uso máximo de memoría de *1677 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta solucion se leen los datos en chunks y aprovechando las iteraciones vamos almacenando en un contador Counter() la cantidad de tweets por cada día y cantidad de tweets por usuario ese día.\n",
    "\n",
    "Finalmente recuperamos el top 10 en cuanto a días con más tweets y usuarios que realizaron la mayor cantidad de tweets esos días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_memory = q1_memory(file_path)\n",
    "display(resultado_q1_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 s ± 175 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 157.44 MiB, increment: 15.60 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory(file_path)\n",
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este enfoque podemos ver que la función **q1_time** tiene un tiempo de ejecución promedio de *4.4 segundos* y un uso máximo de memoría de *157 MiB*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **q1_time_pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como extra mencionar que durante el desarrollo del challenge se intentó utilizar la librería pandas para los enfoques *time* enfoque que no cuida el uso de memoría, pero esta librería tardaba mucho tiempo en leer el conjunto de datos. Por lo que se barajó utilizar la librería **Polars** con su metodo LazyFrame, que es es más rápido que un DataFrame de Pandas gracias a su enfoque de procesamiento perezoso (lazy) que optimiza las operaciones y su capacidad de computación en paralelo aprovechando múltiples núcleos de CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado_q1_time_pandas= q1_time_pandas(file_path)\n",
    "display(resultado_q1_time_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el tiempo que tardó nuestra función en encontrar el resultado y el peak máximo de memoría que utilizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 s ± 583 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "peak memory: 2805.34 MiB, increment: 2319.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_pandas(file_path)\n",
    "%memit q1_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el uso de memoria y el tiempo de computo utilizando Pandas es mayor que utilizando la librería Polars. 5.11 segundos y 2805 MiB de memoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Estructura del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se siguió la misma estructura definida en el challenge, agregando una carpeta donde se almacenaron los datos\n",
    "\n",
    "```css\n",
    "├── README.md\n",
    "├── requirements.txt\n",
    "├── LICENSE\n",
    "├── data\n",
    "│   └── farmers-protest-tweets-2021-2-4.json\n",
    "└── src\n",
    "    ├── challenge.ipynb\n",
    "    ├── q1_time.py\n",
    "    ├── q1_memory.py\n",
    "    ├── q2_time.py\n",
    "    ├── q2_memory.py\n",
    "    ├── q3_time.py\n",
    "    ├── q3_memory.py\n",
    "    └── utils.py\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
